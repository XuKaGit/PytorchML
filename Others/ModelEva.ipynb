{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e095974a",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "- Method for selecting models\n",
    "\n",
    "\n",
    "<p>\n",
    "\n",
    "- **交叉验证:** 就是在训练集中选一部分样本用于测试模型. 保留一部分的训练集数据作为验证集/评估集, 对训练集生成的参数进行测试, 相对客观的判断这些参数对训练集之外的数据的符合程度. \n",
    "\n",
    "## 1. LOOCV\n",
    "\n",
    "- LOOCV (Leave-one-out cross-validation)\n",
    "\n",
    "<p>\n",
    "\n",
    "- 只从可用的数据集中保留一个数据点, 并根据其余数据训练模型. 此过程对每个数据点进行迭代, 比如有n个数据点, 就要重复交叉验证n次.例如一共10个数据, 就交叉验证十次. `test_error` = 所有error的平均数.\n",
    "\n",
    "\n",
    "- **优点:**\n",
    "\n",
    "    - 适合小样本数据集\n",
    "    - 利用所有的数据点，因此偏差将很低\n",
    "\n",
    "- **缺点:**\n",
    "\n",
    "    - 重复交叉验证过程n次导致更高的执行时间.\n",
    "    - 测试模型有效性的变化大. 因为针对一个数据点进行测试, 模型的估计值受到数据点的很大影响. 如果数据点被证明是一个离群值, 它可能导致更大的变化.\n",
    "\n",
    "\n",
    "- `LOOCC`是保留一个数据点, 同样的也可以保留P个数据点作为验证集, 这种方法叫`LPOCV(Leave P Out Cross Validation)`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2.  K-fold Cross Validation\n",
    "\n",
    "\n",
    "- 数据划分: 将数据集随机分成 k 个相同大小的子集(折,fold)\n",
    "- 模型训练与评估: 对于每一个子集, \n",
    "    - 将当前子集用作测试集, 其余 k-1 个子集合并作为训练集.\n",
    "    - 在训练集上训练模型.\n",
    "    - 在测试集上评估模型性能, 通常使用一些指标(如准确率、F1 分数等).\n",
    "- 性能汇总: 收集 k 次评估的性能指标, 计算其平均值和标准差. \n",
    "- 选择最优模型: 通过比较不同模型的平均性能指标, 选择在 k-fold 验证中表现最好的模型. \n",
    "\n",
    "\n",
    "**Remark :** 一般情况下3/5是默认选项, 常建议用K=10\n",
    "\n",
    "## 3. Stratified k-fold cross validation\n",
    "\n",
    "## 4. Adversarial Validation\n",
    "\n",
    "## 5. Cross Validation for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6044a5",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [交叉验证方法汇总](https://blog.csdn.net/WHYbeHERE/article/details/108192957)\n",
    "- [Cross-Validation（交叉验证）详解](https://zhuanlan.zhihu.com/p/24825503)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
