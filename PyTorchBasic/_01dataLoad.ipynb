{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5158c9",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb50f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available() # Check if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adce74",
   "metadata": {},
   "source": [
    "### 1. `help()` & `dir()`\n",
    "\n",
    "`pytorch`(a package) 就像一个工具箱, 有不同的分隔区, 分隔区里有不同的工具.探索工具箱, 两个道具:\n",
    "\n",
    "- dir() 函数：能让我们知道工具箱以及工具箱中的分隔区有什么东西(打开，看见)\n",
    "- help() 函数：能让我们知道每个工具是如何使用的，工具的使用方法(说明书)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb12b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'BFloat16Storage', 'BFloat16Tensor', 'BoolStorage', 'BoolTensor', 'ByteStorage', 'ByteTensor', 'CUDAGraph', 'CharStorage', 'CharTensor']\n",
      "_____________________________\n",
      "Help on _SpecialForm in module typing:\n",
      "\n",
      "typing.Any\n",
      "    Special type indicating an unconstrained type.\n",
      "    \n",
      "    - Any is compatible with every type.\n",
      "    - Any assumed to have all methods.\n",
      "    - All values assumed to be instances of Any.\n",
      "    \n",
      "    Note that all the above statements are true from the point of view of\n",
      "    static type checkers. At runtime, Any should not be used with instance\n",
      "    or class checks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(torch.cuda)[:10])\n",
    "print(\"_____________________________\")\n",
    "help(torch.cuda.Any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47ea66",
   "metadata": {},
   "source": [
    "### 2. DataLoad\n",
    "\n",
    "PyTorch 读取数据涉及两个类: `Dataset` & `Dataloader`\n",
    "\n",
    "#### 2.1 `Dataset`\n",
    "\n",
    "`Dataset`: 提供一种方式, 获取其中需要的数据及其对应的真实的 label 值, 并完成编号. 主要实现以下两个功能:\n",
    "\n",
    "- 如何获取每一个数据及其label\n",
    "- 告诉我们总共有多少的数据\n",
    "\n",
    "`Dataset` 是一个**抽象类**, 所有**数据集**都需要继承这个类, 我们需要将要使用的数据包装为Dataset类. 所有子类都需要重写 `__getitem__` 的方法, 这个方法主要是获取每个数据集及其对应 label, 还可以重写长度类` __len__`\n",
    "\n",
    "\n",
    "#### 2.2 `Dataloader`\n",
    "`Dataloader`: 打包(batch_size), 为后面的神经网络提供不同的数据形式\n",
    "\n",
    "- **shuffle**: 当 shuffle 设置为 True 时， DataLoader 会在每个 **epoch** 开始时随机打乱数据集中的样本. 这有助于提高模型的泛化能力, 防止模型在训练过程中对数据顺序的记忆.\n",
    "- **num_workers**: 多少个进程来读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb93637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from PIL import Image   #读取图片\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0adc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "ants\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#创建一个class，继承 Dataset 类\n",
    "class MyData(Dataset):\n",
    "  def __init__(self,root_dir,label_dir):  \n",
    "    \n",
    "    #通过索引获取图片的地址，需要先创建图片地址的list\n",
    "    self.root_dir=root_dir    \n",
    "    self.label_dir=label_dir\n",
    "    self.path=os.path.join(self.root_dir,self.label_dir)\n",
    "    self.img_path=os.listdir(self.path)  #获得图片下所有的地址\n",
    "    self.transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((128, 128)),  #将图片resize到128*128\n",
    "        torchvision.transforms.ToTensor(),  #将图片转换为tensor\n",
    "    ])\n",
    "\n",
    "  def __getitem__(self, idx):   #idx为编号\n",
    "    #获取每一个图片\n",
    "    img_name=self.img_path[idx]  #名称\n",
    "    img_item_path = os.path.join(self.root_dir,self.label_dir,img_name)  # 每张图片的相对路径\n",
    "    img = Image.open(img_item_path).convert(\"RGB\")  # 确保图像为RGB格式\n",
    "    img = self.transform(img)\n",
    "    label=self.label_dir\n",
    "    return img,label\n",
    " \n",
    "  def __len__(self):    #数据集的长度\n",
    "    return len(self.img_path)\n",
    " \n",
    " \n",
    "#用类创建实例\n",
    "root_dir=\"../Data/hymenoptera_data/train\"\n",
    "ants_label_dir=\"ants\"\n",
    "bees_label_dir=\"bees\"\n",
    "ants_dataset=MyData(root_dir,ants_label_dir)\n",
    "bees_dataset=MyData(root_dir,bees_label_dir)\n",
    " \n",
    " \n",
    "#将ants(124张)和bees(121张)两个数据集进行拼接\n",
    "train_dataset = ants_dataset+bees_dataset\n",
    "\n",
    "\n",
    "img, target = train_dataset[0]\n",
    "print(img.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据形状: torch.Size([16, 3, 128, 128])\n",
      "('ants', 'bees', 'ants', 'ants', 'bees', 'bees', 'ants', 'bees', 'bees', 'bees', 'bees', 'ants', 'bees', 'ants', 'bees', 'ants')\n"
     ]
    }
   ],
   "source": [
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True, drop_last=False)\n",
    "\n",
    "# 获取迭代器\n",
    "# iter(...) 创建一个迭代器，用于遍历 DataLoader 中的批次\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# next(...) 从迭代器中获取下一个批次的数据，返回一个元组 (X, y)，其中 X 是图像张量，y 是对应的标签\n",
    "# 获取第一个 batch\n",
    "first_batch = next(data_iter)\n",
    "\n",
    "# 获取第二个 batch\n",
    "second_batch = next(data_iter)\n",
    "inputs, targets = second_batch\n",
    "\n",
    "print(\"输入数据形状:\", inputs.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4f006",
   "metadata": {},
   "source": [
    "#### Another way to build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ad4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个大小为 (700, 1, 28, 28) 的随机矩阵, 代表700张单通道28*28像素的照片\n",
    "X = torch.randn(700, 1, 28, 28)\n",
    "# X = X.reshape(700, 28, 28)\n",
    "# 生成 700 个随机标签，范围从 1 到 10\n",
    "y = torch.randint(1, 11, (700,))  \n",
    "\n",
    "# Flatten images, create train-test split\n",
    "#X_flat = X.reshape(700, 28 * 28)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_flat, y, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e1f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "first_batch = next(data_iter)\n",
    "first_batch[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmlplus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
